{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0184606a",
   "metadata": {},
   "outputs": [],
   "source": [
    "import time\n",
    "import pandas as pd\n",
    "import torch\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from tqdm import tqdm\n",
    "import polars as pl \n",
    "import json\n",
    "\n",
    "from decoding_strategies_over_custom_gpt import GenerativeModel\n",
    "from gpt import CharTokenizer, get_persons"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7508f14d",
   "metadata": {},
   "outputs": [],
   "source": [
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "pd.set_option('display.max_colwidth', None)\n",
    "pd.set_option('display.max_rows', None)\n",
    "\n",
    "device = \"cuda\" if torch.cuda.is_available() else \"cpu\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cf173e64",
   "metadata": {},
   "outputs": [],
   "source": [
    "tokenizer = CharTokenizer()\n",
    "\n",
    "with open(\"tokenizer_vocab.json\", \"r\", encoding=\"utf-8\") as f:\n",
    "    raw_vocab = json.load(f)\n",
    "    tokenizer._vocab = {int(k): v for k, v in raw_vocab.items()}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9c13931c",
   "metadata": {},
   "outputs": [],
   "source": [
    "VOCAB_SIZE = len(tokenizer.vocab)\n",
    "BATCH_SIZE = 1024\n",
    "MAX_SEQ_LEN = 200\n",
    "N_LAYERS = 6\n",
    "EMBEDDING_SIZE = 128\n",
    "NUM_HEADS = 8\n",
    "NUM_KV_GROUPS = 2\n",
    "NUM_EXPERTS = 16\n",
    "NUM_EXPERTS_PER_TOKEN = 2\n",
    "HEAD_EMBEDDING_SIZE = EMBEDDING_SIZE // NUM_HEADS\n",
    "FCCN_HIDDEN_SIZE = EMBEDDING_SIZE * 4\n",
    "n_epoch = 20"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ce058ab5",
   "metadata": {},
   "outputs": [],
   "source": [
    "model_config = dict(\n",
    "    vocab_size=VOCAB_SIZE,\n",
    "    n_layers=N_LAYERS,\n",
    "    embedding_size=EMBEDDING_SIZE,\n",
    "    num_heads=NUM_HEADS,\n",
    "    num_kv_groups=NUM_KV_GROUPS,\n",
    "    num_experts=NUM_EXPERTS,\n",
    "    num_experts_per_token=NUM_EXPERTS_PER_TOKEN,\n",
    "    head_embedding_size=HEAD_EMBEDDING_SIZE,\n",
    "    fcnn_hidden_size=FCCN_HIDDEN_SIZE,\n",
    "    dropout=0.15,\n",
    ")\n",
    "\n",
    "generator = GenerativeModel(**model_config)\n",
    "\n",
    "generator.load_state_dict(torch.load(\"my_gpt_weights.pt\", map_location=device))\n",
    "\n",
    "generator.to(device)\n",
    "generator.eval()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b6ec363a",
   "metadata": {},
   "outputs": [],
   "source": [
    "def benchmark_parameter(param_name, param_values, prompt, fixed_params):\n",
    "    \"\"\"\n",
    "    Generates text changing one param\n",
    "    \"\"\"\n",
    "    results = []\n",
    "    \n",
    "    print(f\"\\nTesting param: {param_name}\")\n",
    "    \n",
    "    for val in tqdm(param_values):\n",
    "        current_params = fixed_params.copy()\n",
    "        current_params[param_name] = val\n",
    "        \n",
    "        start_time = time.time()\n",
    "        \n",
    "        output_text = generator.generate(\n",
    "            text_input=prompt, \n",
    "            tokenizer=tokenizer, \n",
    "            device=device, \n",
    "            **current_params\n",
    "        )\n",
    "        \n",
    "        end_time = time.time()\n",
    "        \n",
    "        results.append({\n",
    "            \"Parameter\": param_name,\n",
    "            \"Value\": val,\n",
    "            \"Time (sec)\": round(end_time - start_time, 4),\n",
    "            \"Output\": output_text,\n",
    "            \"Length (chars)\": len(output_text)\n",
    "        })\n",
    "        \n",
    "    return pd.DataFrame(results)\n",
    "\n",
    "def plot_results(df, title):\n",
    "    \"\"\"\n",
    "    Plot text length and time generation taken graphs\n",
    "    \"\"\"\n",
    "    fig, axes = plt.subplots(1, 2, figsize=(14, 5))\n",
    "    \n",
    "    # TIME TAKEN\n",
    "    sns.barplot(data=df, x='Value', y='Time (sec)', ax=axes[0], palette='viridis')\n",
    "    axes[0].set_title(f'Time dependence on {df[\"Parameter\"].iloc[0]}')\n",
    "    axes[0].set_xlabel(df[\"Parameter\"].iloc[0])\n",
    "    \n",
    "    # TEXT LEN\n",
    "    sns.lineplot(data=df, x='Value', y='Length (chars)', ax=axes[1], marker='o', color='red')\n",
    "    axes[1].set_title(f'Output length dependence on {df[\"Parameter\"].iloc[0]}')\n",
    "    \n",
    "    plt.suptitle(title)\n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "    \n",
    "    # TABLE\n",
    "    display(df[['Value', 'Time (sec)', 'Output']])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c4b38b62",
   "metadata": {},
   "outputs": [],
   "source": [
    "results = []\n",
    "common_prompt = \"Geralt \""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "12378bb5",
   "metadata": {},
   "source": [
    "## Beam Search\n",
    " do_sample=False -> Deterministic Beam Search"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7d0bc196",
   "metadata": {},
   "outputs": [],
   "source": [
    "base_params_beam = {\n",
    "    \"max_new_tokens\": 40,\n",
    "    \"repetition_penalty\": 1.0,\n",
    "    \"temperature\": 1.0,\n",
    "    \"top_k\": 50,\n",
    "    \"top_p\": 0.9,\n",
    "    \"do_sample\": False  \n",
    "}\n",
    "\n",
    "beam_values = [1, 2, 4, 8]\n",
    "\n",
    "df_beams = benchmark_parameter(\"num_beams\", beam_values, common_prompt, base_params_beam)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "543f773b",
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_results(df_beams, \"Influence of num_beams (Beam Search)\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "90715ab4",
   "metadata": {},
   "source": [
    "## Temperature (sampling)\n",
    "do_sample=True, num_beams=1 -> Sampling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "79cc1cda",
   "metadata": {},
   "outputs": [],
   "source": [
    "base_params_temp = {\n",
    "    \"max_new_tokens\": 50,\n",
    "    \"num_beams\": 1,\n",
    "    \"top_k\": 0,\n",
    "    \"top_p\": 0.0,\n",
    "    \"repetition_penalty\": 1.0,\n",
    "    \"do_sample\": True \n",
    "}\n",
    "\n",
    "temp_values = [0.1, 0.5, 0.8, 1.0, 1.5, 3.0]\n",
    "\n",
    "df_temp = benchmark_parameter(\"temperature\", temp_values, common_prompt, base_params_temp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c17b7d8d",
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_results(df_temp, \"Influence of temperature (Sampling)\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "41877a0a",
   "metadata": {},
   "source": [
    "## Top-K"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5dc39d85",
   "metadata": {},
   "outputs": [],
   "source": [
    "base_params_k = {\n",
    "    \"max_new_tokens\": 40,\n",
    "    \"num_beams\": 1,\n",
    "    \"temperature\": 1.0,\n",
    "    \"top_p\": 0.0,\n",
    "    \"repetition_penalty\": 1.0,\n",
    "    \"do_sample\": True\n",
    "}\n",
    "\n",
    "k_values = [1, 5, 20, 50, 0]\n",
    "\n",
    "df_k = benchmark_parameter(\"top_k\", k_values, common_prompt, base_params_k)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9b1b0e15",
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_results(df_k, \"Influence of top_k\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8c621a76",
   "metadata": {},
   "source": [
    "## Repetition penalty"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c14fff79",
   "metadata": {},
   "outputs": [],
   "source": [
    "loop_prompt = \"Geralt of Rivia is a witcher and Geralt of Rivia\"\n",
    "base_params_rep = {\n",
    "    \"max_new_tokens\": 50,\n",
    "    \"num_beams\": 1,\n",
    "    \"temperature\": 1.0,\n",
    "    \"do_sample\": False, # Greedy search\n",
    "    \"top_k\": 50,\n",
    "    \"top_p\": 0.9,\n",
    "}\n",
    "\n",
    "penalty_values = [1.0, 1.05, 1.1, 1.2, 2.0]\n",
    "\n",
    "df_rep = benchmark_parameter(\"repetition_penalty\", penalty_values, loop_prompt, base_params_rep)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c904149d",
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_results(df_rep, \"Influence of repetition_penalty\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ab3fb7f5",
   "metadata": {},
   "source": [
    "## Comparison"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b6238e90",
   "metadata": {},
   "outputs": [],
   "source": [
    "comparison_data = [\n",
    "    {\"Strategy\": \"Greedy\", \"Time\": df_beams[df_beams['Value'] == 1]['Time (sec)'].values[0]},\n",
    "    {\"Strategy\": \"Beam Search (k=4)\", \"Time\": df_beams[df_beams['Value'] == 4]['Time (sec)'].values[0]},\n",
    "    {\"Strategy\": \"Beam Search (k=8)\", \"Time\": df_beams[df_beams['Value'] == 8]['Time (sec)'].values[0]},\n",
    "    {\"Strategy\": \"Sampling\", \"Time\": df_temp[df_temp['Value'] == 1.0]['Time (sec)'].values[0]},\n",
    "]\n",
    "\n",
    "df_comp = pd.DataFrame(comparison_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4767648c",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(10, 6))\n",
    "sns.barplot(data=df_comp, x='Strategy', y='Time', palette='magma')\n",
    "plt.title('Comparison of generation speed')\n",
    "plt.ylabel('Time (sec)')\n",
    "plt.xticks(rotation=45)\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
