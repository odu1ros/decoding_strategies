{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 1,
      "id": "27637ad9",
      "metadata": {
        "id": "27637ad9"
      },
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "import polars as pl\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "from torch.utils.data import DataLoader\n",
        "from torch.optim import Adam\n",
        "from tqdm import tqdm\n",
        "import json\n",
        "import re\n",
        "\n",
        "from gpt import (\n",
        "    CharTokenizer,\n",
        "    SimpleTextDataset,\n",
        "    collate,\n",
        "    Transformer,\n",
        "    model_memory_size,\n",
        "    fix_seed\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "id": "c3f823d2",
      "metadata": {
        "id": "c3f823d2"
      },
      "outputs": [],
      "source": [
        "fix_seed(42)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "652c01c0",
      "metadata": {
        "id": "652c01c0"
      },
      "source": [
        "# DATA PREPARATION"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "id": "0ca0bcbd",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "0ca0bcbd",
        "outputId": "b5d1f91f-0652-4870-9c10-fc47badf0e46"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "['Она пришла под утро.',\n",
              " 'Вошла осторожно, тихо, бесшумно ступая, плывя по комнате, словно призрак, привидение, а единственным звуком, выдававшим ее движение, был шорох накидки, прикасавшейся к голому телу. Однако именно этот исчезающе тихий, едва уловимый шелест разбудил ведьмака, а может, только вырвал из полусна, в котором он мерно колыхался, словно погруженный в бездонную топь, висящий между дном и поверхностью спокойного моря, среди легонько извивающихся нитей водорослей.',\n",
              " 'Он не пошевелился, даже не дрогнул. Девушка подпорхнула ближе, сбросила накидку, медленно, нерешительно оперлась коленом о край ложа. Он наблюдал за ней из-под опущенных ресниц, не выдавая себя. Девушка осторожно поднялась на постель, легла на него, обхватила бедрами. Опираясь на напряженные руки, скользнула по его лицу волосами. Волосы пахли ромашкой. Решительно и как бы нетерпеливо наклонилась, коснулась сосочком его века, щеки, губ. Он улыбнулся, медленно, осторожно, нежно взял ее руки в свои. Она выпрямилась, ускользая от его пальцев, лучистая, подсвеченная и от этого света нечеткая в туманном отблеске зари. Он пошевелился, но она решительным нажимом обеих рук остановила его и легкими, но настойчивыми движениями бедер добилась ответа.',\n",
              " 'Он ответил. Она уже не избегала его рук, откинула голову, встряхнула волосами. Ее кожа была холодной и поразительно гладкой. Глаза, которые он увидел, когда она приблизила свое лицо к его лицу, были огромными и темными, как глаза русалки.',\n",
              " 'Покачиваясь, он утонул в ромашковом море, а оно взбурлило и зашумело, потеряв покой.',\n",
              " 'Потом говорили, что человек этот пришел с севера, со стороны Канатчиковых ворот. Он шел, а навьюченную лошадь вел под уздцы. Надвигался вечер, и лавки канатчиков и шорников уже закрылись, а улочка опустела. Было тепло, но на человеке был черный плащ, накинутый на плечи. Он обращал на себя внимание.',\n",
              " 'Путник остановился перед трактиром «Старая Преисподняя», постоял немного, прислушиваясь к гулу голосов. Трактир, как всегда в это время, был полон народу.',\n",
              " 'Незнакомец не вошел в «Старую Преисподнюю», а повел лошадь дальше, вниз по улочке к другому трактиру, поменьше, который назывался «У Лиса». Здесь было пустовато – трактир пользовался не лучшей репутацией. Трактирщик поднял голову от бочки с солеными огурцами и смерил гостя взглядом. Чужак, все еще в плаще, стоял перед стойкой твердо, неподвижно и молчал.',\n",
              " '– Что подать?',\n",
              " '– Пива, – сказал незнакомец. Голос был неприятный.']"
            ]
          },
          "execution_count": 3,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "with open(\"data/full_geralt.txt\", \"r\") as file:\n",
        "    raw_content = file.read()\n",
        "\n",
        "corpus = []\n",
        "for line in raw_content.split(\"\\n\"):\n",
        "    cleaned_line = line.strip(\"\\n\")\n",
        "    if not re.search(r\"\\w\", cleaned_line):\n",
        "        continue\n",
        "    corpus.append(cleaned_line)\n",
        "\n",
        "# names = pl.read_parquet(\"data/names.parquet\")\n",
        "# surnames = pl.read_parquet(\"data/surnames.parquet\")\n",
        "\n",
        "# def get_persons(names: pl.DataFrame, surnames: pl.DataFrame, n: int = 100) -> list[str]:\n",
        "#     persons = []\n",
        "#     for _ in range(n):\n",
        "#         sex = np.random.choice([\"m\", \"f\"]).item()\n",
        "#         name = names.filter(pl.col(\"gender\") == sex).sample(1).select(\"text\").item()\n",
        "#         surname = surnames.filter(pl.col(\"gender\") == sex).sample(1).select(\"text\").item()\n",
        "#         persons.append(f\"{name} {surname}\")\n",
        "#     return persons\n",
        "\n",
        "# corpus = get_persons(names, surnames, 10_000)\n",
        "corpus[:10]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "id": "e4428520",
      "metadata": {
        "id": "e4428520"
      },
      "outputs": [],
      "source": [
        "tokenizer = CharTokenizer().fit(corpus)\n",
        "# tokenizer.vocab"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "id": "dd1686ce",
      "metadata": {
        "id": "dd1686ce"
      },
      "outputs": [],
      "source": [
        "# save tokenizer vocab to json\n",
        "with open(\"data/tokenizer_vocab.json\", \"w\", encoding=\"utf-8\") as f:\n",
        "    json.dump(tokenizer.vocab, f, ensure_ascii=False, indent=2)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "id": "9830c511",
      "metadata": {
        "id": "9830c511"
      },
      "outputs": [],
      "source": [
        "VOCAB_SIZE = len(tokenizer.vocab)\n",
        "BATCH_SIZE = 128\n",
        "MAX_SEQ_LEN = 200\n",
        "N_LAYERS = 6\n",
        "EMBEDDING_SIZE = 128\n",
        "NUM_HEADS = 8\n",
        "NUM_KV_GROUPS = 2\n",
        "NUM_EXPERTS = 16\n",
        "NUM_EXPERTS_PER_TOKEN = 2\n",
        "HEAD_EMBEDDING_SIZE = EMBEDDING_SIZE // NUM_HEADS\n",
        "FCCN_HIDDEN_SIZE = EMBEDDING_SIZE * 4\n",
        "n_epoch = 20"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 13,
      "id": "ddfafb37",
      "metadata": {
        "id": "ddfafb37"
      },
      "outputs": [],
      "source": [
        "dataset = SimpleTextDataset(\n",
        "    corpus=corpus,\n",
        "    fitted_tokenizer=tokenizer,\n",
        "    max_seq_length=MAX_SEQ_LEN,\n",
        ")\n",
        "dataloader = DataLoader(\n",
        "    dataset=dataset,\n",
        "    batch_size=BATCH_SIZE,\n",
        "    shuffle=True,\n",
        "    collate_fn=collate\n",
        ")\n",
        "# next(iter(dataloader)).shape"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 14,
      "id": "4a7a888c",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "4a7a888c",
        "outputId": "6934f3a3-6287-42a2-dadc-962c333ef511"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "Transformer(\n",
              "  (_decoder): Decoder(\n",
              "    (_embeddings): Embedding(162, 128, padding_idx=0)\n",
              "    (_positional_embedding): RotaryPositionEmbedding()\n",
              "    (_layers): ModuleList(\n",
              "      (0-5): 6 x DecoderLayer(\n",
              "        (_mha): GroupedQueryAttention(\n",
              "          (_positional_embedding): RotaryPositionEmbedding()\n",
              "          (_Q): Linear(in_features=128, out_features=128, bias=True)\n",
              "          (_K): Linear(in_features=128, out_features=32, bias=True)\n",
              "          (_V): Linear(in_features=128, out_features=32, bias=True)\n",
              "          (_W_proj): Linear(in_features=128, out_features=128, bias=True)\n",
              "          (_q_norm): RMSNorm()\n",
              "          (_k_norm): RMSNorm()\n",
              "        )\n",
              "        (_fcnn): MoEFeedForward(\n",
              "          (_gate): Linear(in_features=128, out_features=16, bias=False)\n",
              "          (_fc1): ModuleList(\n",
              "            (0-15): 16 x Linear(in_features=128, out_features=512, bias=False)\n",
              "          )\n",
              "          (_fc2): ModuleList(\n",
              "            (0-15): 16 x Linear(in_features=128, out_features=512, bias=False)\n",
              "          )\n",
              "          (_fc3): ModuleList(\n",
              "            (0-15): 16 x Linear(in_features=512, out_features=128, bias=False)\n",
              "          )\n",
              "        )\n",
              "        (_rms_norm1): RMSNorm()\n",
              "        (_rms_norm2): RMSNorm()\n",
              "        (_dropout): Dropout(p=0.15, inplace=False)\n",
              "      )\n",
              "    )\n",
              "    (_rms_norm): RMSNorm()\n",
              "  )\n",
              "  (_logits): Linear(in_features=128, out_features=162, bias=False)\n",
              ")"
            ]
          },
          "execution_count": 14,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "model = Transformer(\n",
        "    vocab_size=VOCAB_SIZE,\n",
        "    n_layers=N_LAYERS,\n",
        "    embedding_size=EMBEDDING_SIZE,\n",
        "    num_heads=NUM_HEADS,\n",
        "    num_kv_groups=NUM_KV_GROUPS,\n",
        "    num_experts=NUM_EXPERTS,\n",
        "    num_experts_per_token=NUM_EXPERTS_PER_TOKEN,\n",
        "    head_embedding_size=HEAD_EMBEDDING_SIZE,\n",
        "    fcnn_hidden_size=FCCN_HIDDEN_SIZE,\n",
        "    dropout=0.15,\n",
        ")\n",
        "\n",
        "optimizer = Adam(model.parameters(), lr=4e-3)\n",
        "loss_func = nn.CrossEntropyLoss(reduction='none')\n",
        "\n",
        "epoch_loss = []\n",
        "device = \"cuda\" if torch.cuda.is_available() else 'cpu'\n",
        "model.to(device)\n",
        "model.train()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 15,
      "id": "fdae11b4",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "fdae11b4",
        "outputId": "713c5b7a-19bd-42a9-99a1-1fb2c8750069"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 1\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 239/239 [00:44<00:00,  5.34it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Loss: 1.4653038409963313\n",
            "Epoch 2\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 239/239 [00:44<00:00,  5.36it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Loss: 1.064822441613824\n",
            "Epoch 3\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 239/239 [00:44<00:00,  5.40it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Loss: 0.9292175879538309\n",
            "Epoch 4\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 239/239 [00:44<00:00,  5.42it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Loss: 0.8718519535024795\n",
            "Epoch 5\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 239/239 [00:43<00:00,  5.49it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Loss: 0.8382568835713374\n",
            "Epoch 6\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 239/239 [00:43<00:00,  5.48it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Loss: 0.8147793319933584\n",
            "Epoch 7\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 239/239 [00:43<00:00,  5.50it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Loss: 0.795376094814125\n",
            "Epoch 8\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 239/239 [00:43<00:00,  5.51it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Loss: 0.7799122600375857\n",
            "Epoch 9\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 239/239 [00:43<00:00,  5.54it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Loss: 0.7679623290584676\n",
            "Epoch 10\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 239/239 [00:43<00:00,  5.52it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Loss: 0.7570489709846145\n",
            "Epoch 11\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 239/239 [00:43<00:00,  5.46it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Loss: 0.7472683695070913\n",
            "Epoch 12\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 239/239 [00:44<00:00,  5.41it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Loss: 0.737925934242903\n",
            "Epoch 13\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 239/239 [00:43<00:00,  5.47it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Loss: 0.7297225487282086\n",
            "Epoch 14\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 239/239 [00:43<00:00,  5.50it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Loss: 0.7254211925063672\n",
            "Epoch 15\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 239/239 [00:43<00:00,  5.44it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Loss: 0.7185559694238287\n",
            "Epoch 16\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 239/239 [00:43<00:00,  5.47it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Loss: 0.7113159037035379\n",
            "Epoch 17\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 239/239 [00:43<00:00,  5.50it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Loss: 0.7044421863356395\n",
            "Epoch 18\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 239/239 [00:44<00:00,  5.42it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Loss: 0.7026514834938687\n",
            "Epoch 19\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 239/239 [00:43<00:00,  5.45it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Loss: 0.7001001887241667\n",
            "Epoch 20\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 239/239 [00:43<00:00,  5.49it/s]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Loss: 0.6911696644507691\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\n"
          ]
        }
      ],
      "source": [
        "for i in range(n_epoch):\n",
        "    losses = []\n",
        "    print(f'Epoch {i + 1}')\n",
        "    for x in tqdm(dataloader):\n",
        "        curr_x = x[:, :-1]\n",
        "        next_x = x[:, 1:].clone()\n",
        "        next_x[(curr_x == 0) | (curr_x == 4)] = 0\n",
        "\n",
        "        curr_x = curr_x.to(device)\n",
        "        next_x = next_x.to(device)\n",
        "\n",
        "        logits = model(curr_x)\n",
        "        token_losses = loss_func(logits.transpose(1, 2), next_x.to(torch.long))\n",
        "        loss = token_losses.sum() / (token_losses > 0).sum()\n",
        "        losses.append(loss.item())\n",
        "\n",
        "        loss.backward()\n",
        "        optimizer.step()\n",
        "        optimizer.zero_grad()\n",
        "\n",
        "    epoch_loss.append(np.mean(losses))\n",
        "    print(f'Loss: {epoch_loss[-1]}')\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 16,
      "id": "adc712bd",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "adc712bd",
        "outputId": "99b1a574-237e-4446-89be-37e23e9f513d"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "float32 (PyTorch default): 146.3140 MB\n",
            "bfloat16: 73.1570 MB\n"
          ]
        }
      ],
      "source": [
        "print(f\"float32 (PyTorch default): {model_memory_size(model, input_dtype=torch.float32):.4f} MB\")\n",
        "print(f\"bfloat16: {model_memory_size(model, input_dtype=torch.bfloat16):.4f} MB\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 17,
      "id": "87d2907c",
      "metadata": {
        "id": "87d2907c"
      },
      "outputs": [],
      "source": [
        "torch.save(model.state_dict(), \"data/my_gpt_weights.pt\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "id": "0fa3243d",
      "metadata": {
        "id": "0fa3243d"
      },
      "outputs": [],
      "source": [
        "from decoding_strategies_over_custom_gpt import GenerativeModel"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "id": "817f4d39",
      "metadata": {
        "id": "817f4d39"
      },
      "outputs": [],
      "source": [
        "gen_model = GenerativeModel(\n",
        "    vocab_size=VOCAB_SIZE,\n",
        "    n_layers=N_LAYERS,\n",
        "    embedding_size=EMBEDDING_SIZE,\n",
        "    num_heads=NUM_HEADS,\n",
        "    num_kv_groups=NUM_KV_GROUPS,\n",
        "    num_experts=NUM_EXPERTS,\n",
        "    num_experts_per_token=NUM_EXPERTS_PER_TOKEN,\n",
        "    head_embedding_size=HEAD_EMBEDDING_SIZE,\n",
        "    fcnn_hidden_size=FCCN_HIDDEN_SIZE,\n",
        "    dropout=0.15,\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 21,
      "id": "da788866",
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/plain": [
              "<All keys matched successfully>"
            ]
          },
          "execution_count": 21,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "gen_model.load_state_dict(torch.load(\"data/my_gpt_weights.pt\", map_location=device))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 22,
      "id": "4f022928",
      "metadata": {
        "id": "4f022928",
        "outputId": "38594d89-d4bb-4c75-e350-f83cb6c18a24"
      },
      "outputs": [],
      "source": [
        "# gen_model.load_state_dict(model.state_dict())\n",
        "# gen_model.to(device)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 23,
      "id": "38cd387f",
      "metadata": {
        "id": "38cd387f",
        "outputId": "2ae8c673-083f-4d03-dfd3-bb617358ff81"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Generation Check\n",
            "Input: Геральт\n",
            "Starting Sampling decoding.\n",
            "Strategy: Greedy\n",
            "Strategy: Greedy\n",
            "Strategy: Greedy\n",
            "Strategy: Greedy\n",
            "Strategy: Greedy\n",
            "Strategy: Greedy\n",
            "Strategy: Greedy\n",
            "Strategy: Greedy\n",
            "Strategy: Greedy\n",
            "Strategy: Greedy\n",
            "Strategy: Greedy\n",
            "Strategy: Greedy\n",
            "Strategy: Greedy\n",
            "Strategy: Greedy\n",
            "Strategy: Greedy\n",
            "Strategy: Greedy\n",
            "Strategy: Greedy\n",
            "Strategy: Greedy\n",
            "Strategy: Greedy\n",
            "Strategy: Greedy\n",
            "Output: Геральт поднял голову. Он н\n"
          ]
        }
      ],
      "source": [
        "print(\"Generation Check\")\n",
        "test_prompt = \"Геральт\"\n",
        "print(f\"Input: {test_prompt}\")\n",
        "print(\"Output:\", gen_model.generate(test_prompt, tokenizer, device=device, max_new_tokens=20))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "818753ef",
      "metadata": {
        "id": "818753ef"
      },
      "outputs": [],
      "source": []
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "gpuType": "A100",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "pytorch",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.10.9"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}
